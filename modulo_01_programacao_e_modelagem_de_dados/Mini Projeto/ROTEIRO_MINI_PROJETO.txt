â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      GUIA COMPLETO DE ANÃLISE DE DADOS - PROCEDIMENTO PADRÃƒO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Œ FASE 1: IMPORTAÃ‡ÃƒO E CARREGAMENTO
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ Importar bibliotecas essenciais:
  import pandas as pd
  import numpy as np
  import matplotlib.pyplot as plt
  import seaborn as sns

âœ“ Carregar o dataset:
  df = pd.read_csv('arquivo.csv')
  # Alternativas: pd.read_excel(), pd.read_json(), pd.read_sql()

âœ“ Primeira visualizaÃ§Ã£o:
  df.head()        # Primeiras 5 linhas
  df.tail()        # Ãšltimas 5 linhas
  df.sample(10)    # 10 linhas aleatÃ³rias


ğŸ“Œ FASE 2: EXPLORAÃ‡ÃƒO INICIAL
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ Estrutura do dataset:
  df.shape         # (linhas, colunas)
  df.columns       # Nome das colunas
  df.dtypes        # Tipo de cada coluna
  df.info()        # Resumo completo

âœ“ EstatÃ­sticas descritivas:
  df.describe()                    # Apenas numÃ©ricas
  df.describe(include='all')       # Todas as colunas
  df.describe(include='object')    # Apenas categÃ³ricas

âœ“ Valores ausentes:
  df.isnull().sum()                # Total de nulos por coluna
  df.isnull().sum() / len(df)      # Percentual de nulos


ğŸ“Œ FASE 3: LIMPEZA E TRATAMENTO
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ Tratar valores ausentes:
  # Remover linhas com nulos
  df.dropna()
  df.dropna(subset=['coluna_importante'])
  
  # Preencher nulos
  df.fillna(0)                                    # Com zero
  df['coluna'].fillna(df['coluna'].mean())        # Com mÃ©dia
  df['coluna'].fillna(df['coluna'].median())      # Com mediana
  df['coluna'].fillna(df['coluna'].mode()[0])     # Com moda
  df['coluna'].fillna(method='ffill')             # Forward fill
  df['coluna'].fillna(method='bfill')             # Backward fill

âœ“ Remover duplicatas:
  # 1. INVESTIGAR ANTES DE REMOVER (SEMPRE!)
  df.duplicated().sum()                                    # Contar duplicatas totais
  df.duplicated(subset=['col1', 'col2']).sum()            # Duplicatas em colunas especÃ­ficas
  
  # 2. VISUALIZAR duplicatas (incluindo originais)
  duplicatas = df[df.duplicated(keep=False)]              # keep=False mostra TODAS as ocorrÃªncias
  duplicatas_ordenadas = duplicatas.sort_values(by=list(df.columns))
  
  # 3. ANALISAR por combinaÃ§Ã£o de colunas crÃ­ticas
  # Exemplo: Em dados mÃ©dicos, verificar Nome + Data + Resultado do Teste
  df.duplicated(subset=['Name', 'Date', 'Test_Result']).sum()
  
  # 4. ESTRATÃ‰GIAS DE REMOÃ‡ÃƒO
  # OpÃ§Ã£o A: Remover duplicatas COMPLETAS (todas as colunas iguais)
  df_limpo = df.drop_duplicates(keep='first')             # MantÃ©m primeira ocorrÃªncia
  df_limpo = df.drop_duplicates(keep='last')              # MantÃ©m Ãºltima ocorrÃªncia
  
  # OpÃ§Ã£o B: Remover duplicatas em COLUNAS ESPECÃFICAS (mais seguro)
  # Use quando pacientes/clientes podem ter mÃºltiplas entradas legÃ­timas
  df_limpo = df.drop_duplicates(subset=['col1', 'col2', 'col3'], keep='first')
  
  # OpÃ§Ã£o C: Remover apenas se mÃºltiplas colunas-chave forem idÃªnticas
  # Exemplo: Mesma pessoa + mesma data + mesmo resultado = duplicata verdadeira
  df_limpo = df.drop_duplicates(subset=['id', 'date', 'result'], keep='first')

âœ“ Converter tipos de dados:
  df['coluna'] = pd.to_datetime(df['coluna'], errors='coerce')
  df['coluna'] = df['coluna'].astype(int)
  df['coluna'] = df['coluna'].astype(float)
  df['coluna'] = df['coluna'].astype(str)

âœ“ Padronizar textos:
  df['coluna'] = df['coluna'].str.lower()       # MinÃºsculas
  df['coluna'] = df['coluna'].str.upper()       # MaiÃºsculas
  df['coluna'] = df['coluna'].str.title()       # Capitalize
  df['coluna'] = df['coluna'].str.strip()       # Remover espaÃ§os

âœ“ Tratar outliers:
  # Identificar via IQR
  Q1 = df['coluna'].quantile(0.25)
  Q3 = df['coluna'].quantile(0.75)
  IQR = Q3 - Q1
  limite_inferior = Q1 - 1.5 * IQR
  limite_superior = Q3 + 1.5 * IQR
  
  # Remover outliers
  df = df[(df['coluna'] >= limite_inferior) & (df['coluna'] <= limite_superior)]


ğŸ“Œ FASE 4: ENRIQUECIMENTO E FEATURE ENGINEERING
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ Criar novas colunas:
  df['nova_coluna'] = df['col1'] + df['col2']
  df['diferenca'] = df['data_fim'] - df['data_inicio']

âœ“ Extrair informaÃ§Ãµes de datas:
  df['ano'] = df['data'].dt.year
  df['mes'] = df['data'].dt.month
  df['dia'] = df['data'].dt.day
  df['dia_semana'] = df['data'].dt.dayofweek
  df['nome_mes'] = df['data'].dt.month_name()

âœ“ Categorizar valores contÃ­nuos:
  df['faixa'] = pd.cut(df['coluna'], bins=[0, 18, 40, 60, 100], 
                       labels=['Jovem', 'Adulto', 'Meia-idade', 'Idoso'])
  
  df['categoria'] = pd.qcut(df['coluna'], q=4, 
                            labels=['Baixo', 'MÃ©dio', 'Alto', 'Muito Alto'])

âœ“ Aplicar funÃ§Ãµes:
  df['nova'] = df['coluna'].apply(lambda x: x * 2)
  df['nova'] = df.apply(lambda row: row['col1'] + row['col2'], axis=1)


ğŸ“Œ FASE 5: ANÃLISE EXPLORATÃ“RIA (EDA)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ VariÃ¡veis categÃ³ricas:
  df['coluna'].value_counts()                    # Contagem
  df['coluna'].value_counts(normalize=True)      # Percentual
  df.groupby('categoria')['valor'].count()       # Agrupar

âœ“ VariÃ¡veis numÃ©ricas:
  df['coluna'].mean()          # MÃ©dia
  df['coluna'].median()        # Mediana
  df['coluna'].std()           # Desvio padrÃ£o
  df['coluna'].min()           # MÃ­nimo
  df['coluna'].max()           # MÃ¡ximo
  df['coluna'].quantile(0.95)  # Percentil 95

âœ“ AnÃ¡lises cruzadas:
  df.groupby('categoria')['valor'].mean()
  df.groupby(['cat1', 'cat2'])['valor'].sum()
  df.pivot_table(values='valor', index='linha', columns='coluna', aggfunc='mean')
  pd.crosstab(df['col1'], df['col2'])

âœ“ CorrelaÃ§Ãµes:
  df.corr()                              # CorrelaÃ§Ã£o entre numÃ©ricas
  df['col1'].corr(df['col2'])           # CorrelaÃ§Ã£o especÃ­fica


ğŸ“Œ FASE 6: VISUALIZAÃ‡Ã•ES
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ ConfiguraÃ§Ãµes iniciais:
  plt.style.use('seaborn-v0_8')
  sns.set_palette("husl")
  plt.rcParams['figure.figsize'] = (12, 6)

âœ“ GrÃ¡ficos de distribuiÃ§Ã£o:
  # Histograma
  plt.hist(df['coluna'], bins=30)
  df['coluna'].hist()
  
  # KDE (Densidade)
  sns.kdeplot(df['coluna'])
  
  # Box plot
  sns.boxplot(x='categoria', y='valor', data=df)
  
  # Violin plot
  sns.violinplot(x='categoria', y='valor', data=df)

âœ“ GrÃ¡ficos de contagem:
  # Barras
  df['coluna'].value_counts().plot(kind='bar')
  sns.countplot(x='coluna', data=df)
  
  # Barras horizontais
  df['coluna'].value_counts().plot(kind='barh')
  
  # Pizza
  df['coluna'].value_counts().plot(kind='pie', autopct='%1.1f%%')

âœ“ GrÃ¡ficos de relaÃ§Ã£o:
  # Scatter plot
  plt.scatter(df['x'], df['y'])
  sns.scatterplot(x='x', y='y', data=df)
  
  # Linha
  plt.plot(df['x'], df['y'])
  df.plot(x='data', y='valor', kind='line')
  
  # RegressÃ£o
  sns.regplot(x='x', y='y', data=df)

âœ“ GrÃ¡ficos multivariados:
  # Pairplot
  sns.pairplot(df)
  
  # Heatmap de correlaÃ§Ã£o
  sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')
  
  # Facet grid
  g = sns.FacetGrid(df, col='categoria', row='tipo')
  g.map(plt.hist, 'valor')

âœ“ Sempre adicionar:
  plt.title('TÃ­tulo do GrÃ¡fico')
  plt.xlabel('Eixo X')
  plt.ylabel('Eixo Y')
  plt.tight_layout()
  plt.show()


ğŸ“Œ FASE 7: INSIGHTS E CONCLUSÃ•ES
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ Estrutura do relatÃ³rio:
  1. Resumo executivo (principais descobertas)
  2. Metodologia (como foi feito)
  3. AnÃ¡lise detalhada (resultados por tÃ³pico)
  4. Insights principais (5-10 pontos)
  5. RecomendaÃ§Ãµes prÃ¡ticas
  6. LimitaÃ§Ãµes do estudo
  7. PrÃ³ximos passos

âœ“ Perguntas a responder:
  â€¢ Qual Ã© o principal padrÃ£o encontrado?
  â€¢ Existem anomalias ou valores inesperados?
  â€¢ HÃ¡ correlaÃ§Ãµes significativas?
  â€¢ Quais variÃ¡veis tÃªm maior impacto?
  â€¢ O que isso significa para o negÃ³cio?

âœ“ Exportar resultados:
  df.to_csv('dataset_tratado.csv', index=False)
  df.to_excel('relatorio.xlsx', sheet_name='Dados')
  df.to_json('dados.json')


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ’¡ BOAS PRÃTICAS GERAIS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ“ OrganizaÃ§Ã£o:
  â€¢ Separe o cÃ³digo em cÃ©lulas lÃ³gicas
  â€¢ Use markdown para documentar cada etapa
  â€¢ Crie Ã­ndice com links de navegaÃ§Ã£o
  â€¢ Nomeie variÃ¡veis de forma clara

âœ“ CÃ³digo limpo:
  â€¢ Use comentÃ¡rios explicativos
  â€¢ Evite linhas muito longas (mÃ¡x 79 caracteres)
  â€¢ Siga PEP 8 (padrÃ£o Python)
  â€¢ Teste cada cÃ©lula antes de avanÃ§ar

âœ“ VisualizaÃ§Ãµes:
  â€¢ Use paleta de cores consistente
  â€¢ TÃ­tulos e labels sempre presentes
  â€¢ Legendas quando necessÃ¡rio
  â€¢ Tamanho adequado para leitura
  â€¢ Salve grÃ¡ficos importantes: plt.savefig('grafico.png', dpi=300)

âœ“ Performance:
  â€¢ Use .copy() ao criar novos dataframes
  â€¢ Prefira operaÃ§Ãµes vetorizadas ao invÃ©s de loops
  â€¢ Use .inplace=True quando apropriado
  â€¢ Libere memÃ³ria: del variavel_grande

âœ“ Reprodutibilidade:
  â€¢ Defina random_state quando usar aleatoriedade
  â€¢ Documente versÃµes das bibliotecas
  â€¢ Salve dados intermediÃ¡rios importantes
  â€¢ Crie requirements.txt


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ”§ COMANDOS ÃšTEIS - CHEAT SHEET
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VisualizaÃ§Ã£o rÃ¡pida
df.head(n)           df.tail(n)           df.sample(n)
df.shape             df.columns           df.dtypes
df.info()            df.describe()        df.memory_usage()

# SeleÃ§Ã£o
df['coluna']                              df[['col1', 'col2']]
df.loc[linha, coluna]                     df.iloc[indice]
df[df['coluna'] > 10]                     df.query('coluna > 10')

# AgregaÃ§Ã£o
df.groupby('col').sum()                   df.groupby('col').mean()
df.groupby('col').agg(['sum', 'mean'])    df.pivot_table()

# OrdenaÃ§Ã£o
df.sort_values('coluna')                  df.sort_values(['col1', 'col2'])
df.sort_index()                           df.nlargest(n, 'coluna')

# Renomear
df.rename(columns={'old': 'new'})         df.columns = ['novo1', 'novo2']

# Remover
df.drop('coluna', axis=1)                 df.drop([0, 1, 2], axis=0)
df.drop_duplicates()                      df.dropna()

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¯ FLUXO PADRÃƒO RECOMENDADO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. ImportaÃ§Ã£o de bibliotecas
2. Carregamento dos dados
3. ExploraÃ§Ã£o inicial (shape, info, describe)
4. IdentificaÃ§Ã£o de problemas (nulos, duplicatas, outliers)
5. Limpeza e tratamento
6. Feature engineering
7. AnÃ¡lise exploratÃ³ria univariada
8. AnÃ¡lise exploratÃ³ria bivariada/multivariada
9. VisualizaÃ§Ãµes
10. Insights e conclusÃµes
11. ExportaÃ§Ã£o de resultados

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“š RECURSOS ADICIONAIS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DocumentaÃ§Ã£o:
â€¢ pandas: https://pandas.pydata.org/docs/
â€¢ matplotlib: https://matplotlib.org/stable/contents.html
â€¢ seaborn: https://seaborn.pydata.org/
â€¢ numpy: https://numpy.org/doc/

Dica: Use help(funcao) ou funcao? no Jupyter para ver documentaÃ§Ã£o
