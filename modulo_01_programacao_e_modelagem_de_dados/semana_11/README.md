# ğŸ“‚ Semana 11 - Pipeline ETL e AnÃ¡lise de Dados

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Estrutura completa de projeto de anÃ¡lise de dados com pipeline ETL (Extract, Transform, Load) modularizado e organizado seguindo as melhores prÃ¡ticas da indÃºstria.

---

## ğŸ—ï¸ Estrutura do Projeto

```
semana_11/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Dados brutos (nÃ£o processados)
â”‚   â””â”€â”€ processed/              # Dados processados e limpos
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ analise_dados.ipynb     # Notebook Jupyter principal
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py            # InicializaÃ§Ã£o do pacote src
â”‚   â”œâ”€â”€ analysis.py            # FunÃ§Ãµes de anÃ¡lise exploratÃ³ria
â”‚   â”œâ”€â”€ database.py            # ConexÃ£o e operaÃ§Ãµes com banco de dados
â”‚   â””â”€â”€ etl/
â”‚       â”œâ”€â”€ __init__.py        # InicializaÃ§Ã£o do pacote ETL
â”‚       â”œâ”€â”€ extract.py         # ExtraÃ§Ã£o de dados
â”‚       â”œâ”€â”€ transform.py       # TransformaÃ§Ã£o e limpeza
â”‚       â””â”€â”€ load.py            # Carregamento e salvamento
â”‚
â”œâ”€â”€ venv/                       # Ambiente virtual Python
â”œâ”€â”€ requirements.txt            # DependÃªncias do projeto
â””â”€â”€ README.md                   # Este arquivo
```

---

## ğŸ› ï¸ Tecnologias Utilizadas

```python
pandas       # ManipulaÃ§Ã£o de dados
numpy        # ComputaÃ§Ã£o numÃ©rica
matplotlib   # VisualizaÃ§Ãµes
seaborn      # GrÃ¡ficos estatÃ­sticos
openpyxl     # Leitura/escrita Excel
jupyter      # Ambiente interativo
ipykernel    # Kernel Jupyter
pyarrow      # Formato Parquet
```

---

## ğŸ“¦ MÃ³dulos Desenvolvidos

### ğŸ”¹ ETL Package (`src/etl/`)

#### **extract.py** - ExtraÃ§Ã£o de Dados
FunÃ§Ãµes para extrair dados de diferentes fontes:
- `extract_csv()` - Extrai dados de arquivos CSV
- `extract_excel()` - Extrai dados de arquivos Excel
- `extract_multiple_csv()` - Extrai mÃºltiplos CSVs de um diretÃ³rio

#### **transform.py** - TransformaÃ§Ã£o de Dados
FunÃ§Ãµes para limpar e transformar dados:
- `remove_duplicates()` - Remove duplicatas
- `handle_missing_values()` - Trata valores ausentes
- `remove_outliers_iqr()` - Remove outliers usando mÃ©todo IQR
- `normalize_column()` - Normaliza colunas numÃ©ricas
- `convert_data_types()` - Converte tipos de dados

#### **load.py** - Carregamento de Dados
FunÃ§Ãµes para salvar dados processados:
- `save_to_csv()` - Salva em formato CSV
- `save_to_excel()` - Salva em formato Excel
- `save_to_parquet()` - Salva em formato Parquet (otimizado)
- `append_to_csv()` - Adiciona dados a CSV existente
- `load_processed_data()` - Carrega dados processados

### ğŸ”¹ Analysis Module (`src/analysis.py`)

FunÃ§Ãµes para anÃ¡lise exploratÃ³ria:
- `get_summary_statistics()` - EstatÃ­sticas descritivas
- `check_data_quality()` - RelatÃ³rio de qualidade dos dados
- `analyze_correlations()` - AnÃ¡lise de correlaÃ§Ãµes
- `group_analysis()` - AnÃ¡lise agrupada
- `detect_outliers_summary()` - DetecÃ§Ã£o de outliers
- `value_counts_analysis()` - AnÃ¡lise de distribuiÃ§Ã£o de valores

### ğŸ”¹ Database Module (`src/database.py`)

Classe e funÃ§Ãµes para banco de dados SQLite:
- `DatabaseConnection` - Classe para gerenciar conexÃµes
  - `connect()` - Estabelece conexÃ£o
  - `disconnect()` - Fecha conexÃ£o
  - `execute_query()` - Executa queries SELECT
  - `insert_dataframe()` - Insere DataFrame em tabela
  - `create_table_from_dataframe()` - Cria tabela a partir de DataFrame
  - `list_tables()` - Lista tabelas do banco
  - `get_table_info()` - InformaÃ§Ãµes da estrutura da tabela
- `quick_query()` - FunÃ§Ã£o auxiliar para queries rÃ¡pidas

---

## ğŸš€ Como Usar

### 1. Configurar Ambiente Virtual

```powershell
# Navegar atÃ© a pasta do projeto
cd "e:\analise-de-dados-devinhouse\modulo_01_programacao_e_modelagem_de_dados\semana_11"

# Ativar ambiente virtual (no Windows)
.\venv\Scripts\python.exe

# Ou ativar o ambiente (se configurado)
.\venv\Scripts\Activate.ps1
```

### 2. Instalar DependÃªncias

```powershell
# Usando o python do venv
.\venv\Scripts\python.exe -m pip install -r requirements.txt
```

### 3. Usar o Notebook Jupyter

```powershell
# Iniciar Jupyter
.\venv\Scripts\jupyter notebook

# Ou abrir diretamente no VS Code
code notebooks/analise_dados.ipynb
```

---

## ğŸ’¡ Exemplos de Uso

### ExtraÃ§Ã£o de Dados

```python
from etl.extract import extract_csv, extract_excel

# Extrair CSV
df = extract_csv('../data/raw/dados.csv')

# Extrair Excel
df = extract_excel('../data/raw/dados.xlsx', sheet_name='Planilha1')
```

### TransformaÃ§Ã£o de Dados

```python
from etl.transform import remove_duplicates, handle_missing_values, remove_outliers_iqr

# Remover duplicatas
df_clean = remove_duplicates(df, subset=['nome', 'data'])

# Tratar valores ausentes
df_clean = handle_missing_values(df_clean, strategy='drop')

# Remover outliers
df_clean = remove_outliers_iqr(df_clean, columns=['idade', 'valor'])
```

### Carregamento de Dados

```python
from etl.load import save_to_csv, save_to_parquet

# Salvar em CSV
save_to_csv(df_clean, '../data/processed/dados_limpos.csv')

# Salvar em Parquet (formato otimizado)
save_to_parquet(df_clean, '../data/processed/dados_limpos.parquet')
```

### AnÃ¡lise de Dados

```python
from analysis import check_data_quality, analyze_correlations

# Verificar qualidade dos dados
quality_report = check_data_quality(df_clean)

# Analisar correlaÃ§Ãµes
correlation_matrix = analyze_correlations(df_clean, threshold=0.5)
```

### Trabalhar com Banco de Dados

```python
from database import DatabaseConnection

# Criar conexÃ£o
db = DatabaseConnection('../data/processed/database.db')
db.connect()

# Inserir dados
db.insert_dataframe(df_clean, 'tabela_principal', if_exists='replace')

# Executar query
resultado = db.execute_query('SELECT * FROM tabela_principal WHERE idade > 30')

# Fechar conexÃ£o
db.disconnect()
```

---

## ğŸ“Š Workflow Recomendado

1. **Extract** - Coloque dados brutos em `data/raw/`
2. **Transform** - Use funÃ§Ãµes de `transform.py` para limpar
3. **Load** - Salve dados processados em `data/processed/`
4. **Analyze** - Use `analysis.py` para exploraÃ§Ã£o
5. **Visualize** - Crie grÃ¡ficos no Jupyter Notebook
6. **Database** (opcional) - Persista dados em SQLite

---

## ğŸ¯ Boas PrÃ¡ticas Implementadas

âœ… **ModularizaÃ§Ã£o** - CÃ³digo organizado em mÃ³dulos reutilizÃ¡veis  
âœ… **SeparaÃ§Ã£o de Dados** - raw/ e processed/ claramente separados  
âœ… **DocumentaÃ§Ã£o** - Docstrings em todas as funÃ§Ãµes  
âœ… **Type Hints** - Tipos especificados para melhor legibilidade  
âœ… **Tratamento de Erros** - Try/except com mensagens claras  
âœ… **Ambiente Virtual** - Isolamento de dependÃªncias  
âœ… **Requirements.txt** - DependÃªncias versionadas  
âœ… **Feedback Visual** - Emojis e prints informativos  

---

## ğŸ“š Recursos Adicionais

### Formatos de Dados Suportados:
- **CSV** - Arquivos de texto separados por vÃ­rgula
- **Excel** - Planilhas .xlsx e .xls
- **Parquet** - Formato colunar otimizado
- **SQLite** - Banco de dados relacional

### MÃ©todos de Limpeza:
- **Duplicatas** - RemoÃ§Ã£o inteligente
- **Valores Ausentes** - Drop, fill, mean, median
- **Outliers** - MÃ©todo IQR (Interquartile Range)
- **NormalizaÃ§Ã£o** - Min-Max Scaling e Z-Score

---

## ğŸ‘¨â€ğŸ’» Autor

**Augusto Costa**  
Estudante de AnÃ¡lise de Dados - DevInHouse V4

ğŸ“§ Email: augustoccostamg@gmail.com  
ğŸ’¼ LinkedIn: [Augusto CÃ©sar da Costa](https://www.linkedin.com/in/augusto-c%C3%A9sar-da-costa-768516218)  
ğŸ™ GitHub: [@augustocosta-17](https://github.com/augustocosta-17)

---

## ğŸ“ Notas

- Este projeto foi desenvolvido como parte do curso DevInHouse V4
- A estrutura segue padrÃµes da indÃºstria para projetos de Data Science
- Todos os mÃ³dulos sÃ£o independentes e podem ser usados separadamente
- O cÃ³digo Ã© totalmente documentado e pronto para produÃ§Ã£o

---

[â¬…ï¸ Voltar ao MÃ³dulo 01](../README.md)
